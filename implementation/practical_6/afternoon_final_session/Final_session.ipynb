{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wi1HO4bSLXma"
   },
   "source": [
    "# ACSE-8: En el tintero\n",
    "*Friday 14 May 2021*\n",
    "\n",
    "\n",
    "I would like to start this last session by thanking the ACSE-8 teaching team:\n",
    "\n",
    "#### `Oscar Bates`\n",
    "#### `Carlos Cueto`\n",
    "#### `Zainab D Titus`\n",
    "#### `Olivier Dubrule`\n",
    "#### `Yao Jiashun`\n",
    "#### `Deborah Pelacani Cruz`\n",
    "#### `George Strong`\n",
    "\n",
    "<br>\n",
    "\n",
    "and obviously:\n",
    "\n",
    "#### `you, the students`\n",
    "\n",
    "I hope you enjoyed the experience as much as we (at least I) have, and have found ACSE-8 instructive and productive.\n",
    "\n",
    "<br>\n",
    "\n",
    "In this final session, we will provide resources to complement the concepts learned during ACSE-8 based on your mentimeter feedback.\n",
    "\n",
    "We will also introduce a (short) list of topics we could not cover during the course due to its introductory nature, and lack of time. This list is not complete by any means: it only reflects our awareness of the field and it is heavily influenced by our active interests.\n",
    "\n",
    "\n",
    "Outline of today's session:\n",
    "\n",
    "1. wandb.ai\n",
    "  - Debbie\n",
    "2. How do we use ML:\n",
    "  - George\n",
    "  - Zainab\n",
    "  - Carlos\n",
    "  - Oscar\n",
    "  - Olivier\n",
    "3. Topics to revisit (based on mentimeter)\n",
    "4. Other topics in ML (with a bias ðŸ˜„)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "a10KLJ-HQuaW"
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "HE3A4ULGMXWr"
   },
   "source": [
    "# 1. wandb.ai\n",
    "\n",
    "[weight and biases website](https://wandb.ai/)\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "<img src=\"https://assets.website-files.com/5ac6b7f2924c656f2b13a88c/6077a58f02c7ef0e37fde627_weights%20and%20biases%20workspace.jpg\" alt=\"network\" width=\"600\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "E03N730zQ3IO"
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "eVaFGuYSMyuX"
   },
   "source": [
    "# 2. How do we use ML\n",
    "\n",
    "Machine learning in...\n",
    "\n",
    "  - George: **ultrasound brain imaging with ML**\n",
    "  - Zainab: **geothermal reservoir-well systems**\n",
    "  - Carlos: **absorbing boundaries in PDEs**\n",
    "  - Oscar: **uncertainty quantification in medical imaging**\n",
    "  - Olivier: **ML-driven seismic inversion**"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "lux4kkFsQ53L"
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "sVNB2DwyM2Kz"
   },
   "source": [
    "# 3. Popular topics from mentimeter polls\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/acse-2020/ACSE-8/main/implementation/practical_6/afternoon_final_session/Figs/menti_1.png?token=ABNZJPZCS2FU74WUTMGIDY3AUUSMM\" alt=\"network\" width=\"800\"/>\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/acse-2020/ACSE-8/main/implementation/practical_6/afternoon_final_session/Figs/menti_2.png?token=ABNZJP4BYT7YKX6YN5JQ4P3AUUSNM\" alt=\"network\" width=\"800\"/>\n",
    "\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/acse-2020/ACSE-8/main/implementation/practical_6/afternoon_final_session/Figs/menti_3.png?token=ABNZJPYOC2A2BHFNW2XGB63AUYAZM\" alt=\"network\" width=\"800\"/>\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "Q23lnyFpHKZy"
   },
   "source": [
    "\n",
    "### In order of perceived popularity:\n",
    "\n",
    "## PCA:\n",
    "\n",
    "[Baby steps](https://towardsdatascience.com/understanding-pca-fae3e243731d) \\\n",
    "[<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTw-qi8a5py_kmXLlO0Zdlmj-RC1iJFJVDg1A&usqp=CAU\" alt=\"network\" width=\"100\"/>](https://towardsdatascience.com/understanding-pca-fae3e243731d) \n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "[I think I know what I am doing](https://en.wikipedia.org/wiki/Principal_component_analysis) \\\n",
    "[<img src=\"https://raw.githubusercontent.com/acse-2020/ACSE-8/main/implementation/practical_6/afternoon_final_session/Figs/bill.jpg?token=ABNZJP4NCE46RHQF47MRTB3AU2AE4\" alt=\"intermediate\" width=\"150\"/>](https://en.wikipedia.org/wiki/Principal_component_analysis) \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "[Grown ups](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf) (from page 561) \\\n",
    "[<img src=\"https://www.wmky.org/sites/wmky/files/201908/coltrane.jpg\" alt=\"network\" width=\"200\"/>](http://users.isr.ist.utl.pt/~wurmd/Livros/school/Bishop%20-%20Pattern%20Recognition%20And%20Machine%20Learning%20-%20Springer%20%202006.pdf) \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "## Regularisation:\n",
    "\n",
    "[Baby steps](https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/) \\\n",
    "[<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTw-qi8a5py_kmXLlO0Zdlmj-RC1iJFJVDg1A&usqp=CAU\" alt=\"network\" width=\"100\"/>](https://machinelearningmastery.com/weight-regularization-to-reduce-overfitting-of-deep-learning-models/) \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "[I think I know what I am doing](https://en.wikipedia.org/wiki/Regularization_(mathematics) \\\n",
    "[<img src=\"https://raw.githubusercontent.com/acse-2020/ACSE-8/main/implementation/practical_6/afternoon_final_session/Figs/bill.jpg?token=ABNZJP4NCE46RHQF47MRTB3AU2AE4\" alt=\"intermediate\" width=\"150\"/>](https://en.wikipedia.org/wiki/Regularization_(mathematics)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "[Grown ups](https://www.deeplearningbook.org/contents/regularization.html) (chapter 7) \\\n",
    "[<img src=\"https://mediad.publicbroadcasting.net/p/shared/npr/styles/x_large/nprshared/202103/237101265.jpg\" width=\"200\"/>](https://www.deeplearningbook.org/contents/regularization.html) \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Batch normalization:\n",
    "\n",
    "[Baby steps](https://www.kdnuggets.com/2020/08/batch-normalization-deep-neural-networks.html) \\\n",
    "[<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTw-qi8a5py_kmXLlO0Zdlmj-RC1iJFJVDg1A&usqp=CAU\" alt=\"network\" width=\"100\"/>](https://www.kdnuggets.com/2020/08/batch-normalization-deep-neural-networks.html) \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "[Grown ups](https://arxiv.org/pdf/1502.03167.pdf) \\\n",
    "[<img src=\"https://www.arts.gov/sites/default/files/styles/portrait/public/images/Sonny-Rollins-by-John-Abbott-BW.jpg?itok=B-tm8zRE\" width=\"200\"/>](https://arxiv.org/pdf/1502.03167.pdf) \n",
    "\n",
    "\n",
    "[and](https://arxiv.org/pdf/1805.11604.pdf)\n",
    "\n",
    "[<img src=\"https://www.thewire.co.uk/img/scale/940/952/2015/06/15/Ornette_Coleman_credit_William_Claxton_Courtesy_Demont_Photo_Management.jpg\" width=\"200\"/>](https://arxiv.org/pdf/1805.11604.pdf) \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "## Computational graphs and automatic differentiation:\n",
    "\n",
    "[Baby steps](https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/) \\\n",
    "[<img src=\"https://encrypted-tbn0.gstatic.com/images?q=tbn:ANd9GcTw-qi8a5py_kmXLlO0Zdlmj-RC1iJFJVDg1A&usqp=CAU\" alt=\"network\" width=\"100\"/>](https://blog.paperspace.com/pytorch-101-understanding-graphs-and-automatic-differentiation/) \n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "[Grown ups](https://www.youtube.com/watch?v=MswxJw-8PvE) \\\n",
    "[<img src=\"https://www.sandybrownjazz.co.uk/Features/Features%20Images/Albert%20Ayler%20b.jpg\" alt=\"network\" width=\"200\"/>](https://www.youtube.com/watch?v=MswxJw-8PvE) \n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "## More time:\n",
    "Point taken and thanks for the feedback. As you have seen we are trying to cover a lot of topics.\n",
    "\n",
    "We have made compromises and settled on a course that will give you all the tools you need to develop your ML forward in three weeks.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Backpropagation:\n",
    "Already covered in the tutorials (we hope).\n",
    "\n",
    "<br>\n",
    "\n",
    "## Pytorch\n",
    "\n",
    "For me, becoming fluent in [`PyTorch`](https://pytorch.org/) will never be a quick process. I recommend that you read not only the [documentation](https://pytorch.org/docs/stable/generated/torch.nn.KLDivLoss.html#torch.nn.KLDivLoss), but also the [source code](https://pytorch.org/docs/stable/_modules/torch/nn/modules/loss.html#KLDivLoss) where you will find all the implementation details you need to fully understand how to use its functionality.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Coursework questions:\n",
    "You know what the courseworks are by now. \n",
    "\n",
    "<br>\n",
    "\n",
    "## ML career session\n",
    "\n",
    "This is a very good idea but unfortunately we did not have time to cover it properly. I will keep it in mind and try to make room for it in the future.\n",
    "\n",
    "Having said that, Yao will talk about opportunities to do a PhD in the department.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Big picture overview\n",
    "That's what we are trying to do today... we'll see how far we get!\n",
    "\n",
    "<br>\n",
    "\n",
    "## What projects are we working on:\n",
    "Go watch the presentations by the team earlier this afternoon!\n",
    "\n",
    "<br>\n",
    "\n",
    "## More fun:\n",
    "Even more? go back to practical 5 and you will be able to generate your own jokes.\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "yl94mi0WRB5W"
   },
   "source": [
    "<br>\n",
    "\n",
    "---\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "vt67ijk5MaGy"
   },
   "source": [
    "# 4. Other topics in ML (with a bias ðŸ˜„)\n",
    "\n",
    "In here you will find references and links to a range of topics that were mentioned during the course, or that we find interesting, or that are just pure fun.\n",
    "\n",
    "\n",
    "## **Reinforcement learning**\n",
    "\n",
    "\n",
    "*Reinforcement learning (RL) is an area of machine learning concerned with how intelligent agents ought to take actions in an environment in order to maximize the notion of cumulative reward* [from wikipedia](https://en.wikipedia.org/wiki/Reinforcement_learning)\n",
    "\n",
    "[foundation papers](https://spinningup.openai.com/en/latest/spinningup/keypapers.html)\n",
    "\n",
    "#### Application example:\n",
    "\n",
    "\n",
    "<img src=\"https://upload.wikimedia.org/wikipedia/commons/2/2a/FloorGoban.JPG\" alt=\"go\" width=\"200\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "AlphaGo Zero: learning from scratch\n",
    "\n",
    "[blog](https://deepmind.com/blog/article/alphago-zero-starting-scratch)\n",
    "\n",
    "[paper](https://www.nature.com/articles/nature24270.epdf?author_access_token=VJXbVjaSHxFoctQQ4p2k4tRgN0jAjWel9jnR3ZoTv0PVW4gB86EEpGqTRDtpIz-2rmo8-KG06gqVobU5NSCFeHILHcVFUeMsbvwS-lxjqQGg98faovwjxeTUgZAUMnRQ)\n",
    "\n",
    "[movie](https://www.youtube.com/watch?v=8tq1C8spV_g)\n",
    "\n",
    "### In Go there are ~ $2 \\cdot 10^{170}$ possible board configurations (the universe has $10^{80}$ atoms)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/3840/1*12j-WcpFxW_v9-vBQkdHwA.png\" alt=\"go\" width=\"800\"/>\n",
    "\n",
    "<br>\n",
    "\n",
    "## **Transformers**\n",
    "\n",
    "\n",
    "<img src=\"https://www.researchgate.net/publication/344197785/figure/fig2/AS:934416989843456@1599793779015/Transformer-model-architecture-described-in-Attention-Is-All-You-Need-6.ppm\" alt=\"transformer\" width=\"300\">\n",
    "\n",
    "Transformers were introduced in the paper: [Attention is all you need](https://arxiv.org/pdf/1706.03762.pdf). At its core, transformers introduce the concept of attention to replace recurrence. They handle sequential data (like RNNs or LSTMs) but do not require the input to be sequential (better parallelisation and therefore ability to handle bigger datasets). They are considered the best solution for NLP (Natural Language Processing) problems, with pretrained systems like [BERT](https://arxiv.org/pdf/1810.04805.pdf) and [GPT-3](https://arxiv.org/pdf/2005.14165.pdf) becoming very popular.\n",
    "\n",
    "<br>\n",
    "\n",
    "## Multimodal Neurons\n",
    "\n",
    "<img src=\"https://cdn.openai.com/research-covers/multimodal-neurons/2x-no-mark-animated-poster.jpg\" width=\"200\">\n",
    "\n",
    "*In 2005, a letter published in Nature described human neurons responding to specific people, such as Jennifer Aniston or Halle Berry . The exciting thing wasnâ€™t just that they selected for particular people, but that they did so regardless of whether they were shown photographs, drawings, or even images of the personâ€™s name. The neurons were multimodal. As the lead author would put it: \"You are looking at the far end of the transformation from metric, visual shapes to conceptualâ€¦ information.\" Quiroga's full quote, from reads: \"I think thatâ€™s the excitement to these results. You are looking at the far end of the transformation from metric, visual shapes to conceptual memory-related information. It is that transformation that underlies our ability to understand the world. Itâ€™s not enough to see something familiar and match it. Itâ€™s the fact that you plug visual information into the rich tapestry of memory that brings it to life.\" We elided the portion discussing memory since it was less relevant.*\n",
    "\n",
    "*We report the existence of similar multimodal neurons in artificial neural networks. This includes neurons selecting for prominent public figures or fictional characters, such as Lady Gaga or Spiderman.**\n",
    "\n",
    "https://openai.com/blog/multimodal-neurons/\n",
    "\n",
    "[[paper]](https://distill.pub/2021/multimodal-neurons/)\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## Intriguing properties of neural networks \n",
    "\n",
    "In [this paper](https://arxiv.org/pdf/1312.6199.pdf), the authors (you will see a familiar name in the list) study how networks fail to classify images in certain situations\n",
    "\n",
    "<img src=\"https://vitalab.github.io/article/images/IntriguingProperties/05.jpg\" width=\"800\">\n",
    "\n",
    "The images on the right column of each of the two panels are classified as ostriches!\n",
    "\n",
    "<img src=\"https://pbs.twimg.com/media/EBO6OT-UwAAnJ-n.jpg:large\" width=\"300\">\n",
    "\n",
    "<br>\n",
    "\n",
    "## GLOM\n",
    "\n",
    "\n",
    "How to represent part-whole hierarchies in a neural network [paper](https://arxiv.org/pdf/2102.12627.pdf)\n",
    "\n",
    "Great [talk](https://gtc21.event.nvidia.com/media/How%20to%20Represent%20Part-Whole%20Hierarchies%20in%20a%20Neural%20Net%20%5BS33159%5D/1_pcj05a24) in GTC 2021 by Hinton introducing the concept. (you may need to register but I think it is free).\n",
    "\n",
    "<br>\n",
    "\n",
    "## Geometric learning\n",
    "\n",
    "Michael Bronstein is the ***Chair in Machine Learning and Pattern Recognition*** in the department of computing here at Imperial.\n",
    "\n",
    "*Geometric deep learningis an umbrella term for emergingtechniques  attempting  to  generalize  (structured)  deep  neuralmodels  to  non-Euclidean  domains  such  as  graphs  and  man-ifolds.  The  purpose  of  this  paper  is  to  overview  differentexamples  of  geometric  deep  learning  problems  and  presentavailable  solutions,  key  difficulties,  applications,  and  futureresearch directions in this nascent field.* (from the abstract of the paper).\n",
    "\n",
    "\n",
    "[[paper]](https://arxiv.org/pdf/1611.08097.pdf)\n",
    "\n",
    "[[talk]](https://www.youtube.com/watch?v=8IwJtFNXr1U)\n",
    "\n",
    "<br>\n",
    "\n",
    "## Interesting conferences to keep an eye on:\n",
    "\n",
    "- NEURIPS (https://nips.cc/)\n",
    "- GTC (https://www.nvidia.com/en-us/gtc/)\n",
    "- and many more (check [this](https://www.hpe.com/us/en/insights/articles/the-top-ai-and-machine-learning-conferences-to-attend-in-2020-1911.html))\n",
    "\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "## Links and references in the course materials\n",
    "\n",
    "Check the links and references in the course materials (for example, the different flavours of GANs presented by Yao, or the very deep VAEs links in Oscar's slides).\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "QWOU5BrKTir7"
   },
   "source": [
    "<br>\n",
    "\n",
    "---- \n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6kVvOyLvDjlD"
   },
   "source": [
    "## Ethics:\n",
    "\n",
    "We have not discussed ethics in this introductory course, but I would like to leave you with some materials for you to read and think about it:\n",
    "\n",
    "- European Parliamentary Research Service: [The ethics of artificial intelligence: Issues and initiatives](https://www.europarl.europa.eu/RegData/etudes/STUD/2020/634452/EPRS_STU(2020)634452_EN.pdf)\n",
    "- Ethical principles in machine learning and artificial intelligence: cases from the field and possible ways forward [[paper]](https://www.nature.com/articles/s41599-020-0501-9.pdf)\n",
    "- The Institute for Ethical AI & Machine Learning: (https://ethical.institute/)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "V8p37-uROzao"
   },
   "source": [
    "# Finally:\n",
    "\n",
    "Keep in mind that ML is an emerging field and provides fantastic tools to solve complex problems. As such, and keeping in mind the bias we have as researchers, we are still trying to understand when and where to use this tools in order to extract machimum value in important societal challenges (classifying cats and dogs is fun, but solving scientific problems is better!)\n",
    "\n",
    "<br>\n",
    "\n",
    "From here:\n",
    "\n",
    "<img src=\"https://imgs.xkcd.com/comics/machine_learning.png\" width=\"300\"> \\\n",
    "[XKCD 1838](https://xkcd.com/1838/)\n",
    "\n",
    "<br>\n",
    "\n",
    "to here:\n",
    "\n",
    "\n",
    "<img src=\"https://static.cambridge.org/binary/version/id/urn:cambridge.org:id:binary:20201223160655562-0200:S2053470120000311:S2053470120000311_fig10.png\" width=\"600\"> \\\n",
    "[Deep variational autoencoders](https://www.cambridge.org/core/journals/design-science/article/generation-of-geometric-interpolations-of-building-types-with-deep-variational-autoencoders/F4899EC122329816CD137503D8118875)\n",
    "\n",
    "<br>\n",
    "\n",
    "and here:\n",
    "\n",
    "<img src=\"https://paperswithcode.com/media/methods/Screen_Shot_2020-07-05_at_3.54.24_PM_d9gQdLL.png\" width=\"600\"> \\\n",
    "[cycleGANs](https://arxiv.org/pdf/1703.10593.pdf)\n",
    "\n",
    "\n",
    "<br>\n",
    "\n",
    "<br>\n",
    "\n",
    "\n",
    "# Many thanks everybody for attending the course and we wish you the best in your future professional careers (maybe in ML)!!\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "Last_day.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
