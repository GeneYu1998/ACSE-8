{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Morning_Session_6_GANs_Exercise_conditionalGAN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ZoLwAbmt8ZxT",
        "outputId": "768776a7-bbb1-49af-e503-f62e5f9c6a2e"
      },
      "source": [
        "!pip install livelossplot\n",
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Requirement already satisfied: livelossplot in /usr/local/lib/python3.7/dist-packages (0.5.4)\n",
            "Requirement already satisfied: bokeh in /usr/local/lib/python3.7/dist-packages (from livelossplot) (2.3.1)\n",
            "Requirement already satisfied: ipython in /usr/local/lib/python3.7/dist-packages (from livelossplot) (5.5.0)\n",
            "Requirement already satisfied: matplotlib in /usr/local/lib/python3.7/dist-packages (from livelossplot) (3.2.2)\n",
            "Requirement already satisfied: packaging>=16.8 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (20.9)\n",
            "Requirement already satisfied: PyYAML>=3.10 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.13)\n",
            "Requirement already satisfied: tornado>=5.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (5.1.1)\n",
            "Requirement already satisfied: numpy>=1.11.3 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (1.19.5)\n",
            "Requirement already satisfied: python-dateutil>=2.1 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.8.1)\n",
            "Requirement already satisfied: pillow>=7.1.0 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (7.1.2)\n",
            "Requirement already satisfied: typing-extensions>=3.7.4 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (3.7.4.3)\n",
            "Requirement already satisfied: Jinja2>=2.7 in /usr/local/lib/python3.7/dist-packages (from bokeh->livelossplot) (2.11.3)\n",
            "Requirement already satisfied: pygments in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (2.6.1)\n",
            "Requirement already satisfied: decorator in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.4.2)\n",
            "Requirement already satisfied: pickleshare in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.7.5)\n",
            "Requirement already satisfied: prompt-toolkit<2.0.0,>=1.0.4 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (1.0.18)\n",
            "Requirement already satisfied: setuptools>=18.5 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (56.1.0)\n",
            "Requirement already satisfied: traitlets>=4.2 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (5.0.5)\n",
            "Requirement already satisfied: simplegeneric>0.8 in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (0.8.1)\n",
            "Requirement already satisfied: pexpect; sys_platform != \"win32\" in /usr/local/lib/python3.7/dist-packages (from ipython->livelossplot) (4.8.0)\n",
            "Requirement already satisfied: kiwisolver>=1.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (1.3.1)\n",
            "Requirement already satisfied: cycler>=0.10 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (0.10.0)\n",
            "Requirement already satisfied: pyparsing!=2.0.4,!=2.1.2,!=2.1.6,>=2.0.1 in /usr/local/lib/python3.7/dist-packages (from matplotlib->livelossplot) (2.4.7)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.7/dist-packages (from python-dateutil>=2.1->bokeh->livelossplot) (1.15.0)\n",
            "Requirement already satisfied: MarkupSafe>=0.23 in /usr/local/lib/python3.7/dist-packages (from Jinja2>=2.7->bokeh->livelossplot) (1.1.1)\n",
            "Requirement already satisfied: wcwidth in /usr/local/lib/python3.7/dist-packages (from prompt-toolkit<2.0.0,>=1.0.4->ipython->livelossplot) (0.2.5)\n",
            "Requirement already satisfied: ipython-genutils in /usr/local/lib/python3.7/dist-packages (from traitlets>=4.2->ipython->livelossplot) (0.2.0)\n",
            "Requirement already satisfied: ptyprocess>=0.5 in /usr/local/lib/python3.7/dist-packages (from pexpect; sys_platform != \"win32\"->ipython->livelossplot) (0.7.0)\n",
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "lMGyZY7-8lOc",
        "outputId": "e0b0911a-1ec9-4128-dfc6-0bef8453561f"
      },
      "source": [
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Populating the interactive namespace from numpy and matplotlib\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "3PXeK7kDasiK"
      },
      "source": [
        "# Morning Session 6: Conditional Generative Adversarial Networks (cGANs)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dnSCs9PObaUJ"
      },
      "source": [
        "Conditional GANs enables the generation of realistic data that matches the given labels -- greatly improves the value of GANs in real practises.\n",
        "\n",
        "![](https://miro.medium.com/max/700/1*Vjo1df-yPFks2e_-TbdWdQ.png)\n",
        "\n",
        "Image credit: [medium blog](https://medium.com/@ma.bagheri/a-tutorial-on-conditional-generative-adversarial-nets-keras-implementation-694dcafa6282)\n",
        "\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KK2h_09p81r7",
        "outputId": "a76e53af-5eb8-4f7b-e842-b680bc2d7009"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.autograd import Variable\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "import random \n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Cuda installed! Running on GPU!\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Bjd64qAc9M9r"
      },
      "source": [
        "## Train a conditional GAN\n",
        "**How to put label into the network?**\n",
        "* **Simply input it into the networks togather with the latent vector / data**\n",
        "\n",
        "\n",
        "Latent vector length: 100 Length of the label vector: 10\n",
        "\n",
        "Network G:\n",
        "\n",
        "0. Concatenate the z and z_label here using torch.cat()\n",
        "1. Layer 1 for the latent vector: 110 -> 256\n",
        "2. Layer 2 for the label vector: 256 -> 512\n",
        "3. Layer 2: 512 -> 1024\n",
        "4. Layer 4: 1024 -> 784 (size of a MNIST image) \n",
        "\n",
        "Apply leaky_relu(alpha=0.2) activation functions for layers 1-3, and tanh to layer 4.\n",
        "\n",
        "Network D:\n",
        "\n",
        "0. Concatenate the z and z_label here using torch.cat()\n",
        "1. Layer 1: 794 -> 1024\n",
        "2. Layer 2: 1024 -> 512\n",
        "3. Layer 3: 512 -> 256\n",
        "4. Layer 4: 256 -> 1\n",
        "\n",
        "Apply leaky_relu(alpha=0.2) activation functions and dropout for layers 1-3, and sigmoid to layer 4.\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EAC2gDEpBlPt"
      },
      "source": [
        "class Generator(nn.Module):\n",
        "    def __init__(self, g_input_dim=100, g_input_dim_label=10, g_output_dim=28*28):\n",
        "        super().__init__()       \n",
        "        #*** only change the first layer here ***\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features*2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features*2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, g_output_dim)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x, x_label): \n",
        "        #*** Concatenate the x and x_label with torch.cat ***\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        return torch.tanh(self.fc4(x))\n",
        "    \n",
        "class Discriminator(nn.Module):\n",
        "    def __init__(self, d_input_dim=28*28, d_label_input_dim=10):\n",
        "        super().__init__()\n",
        "        #*** Concatenate the x and x_label with torch.cat ***\n",
        "        self.fc2 = nn.Linear(self.fc1.out_features, self.fc1.out_features//2)\n",
        "        self.fc3 = nn.Linear(self.fc2.out_features, self.fc2.out_features//2)\n",
        "        self.fc4 = nn.Linear(self.fc3.out_features, 1)\n",
        "    \n",
        "    # forward method\n",
        "    def forward(self, x, x_label):\n",
        "        #*** Concatenate the x and x_label with torch.cat ***\n",
        "        x = F.leaky_relu(self.fc1(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc2(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        x = F.leaky_relu(self.fc3(x), 0.2)\n",
        "        x = F.dropout(x, 0.3)\n",
        "        return torch.sigmoid(self.fc4(x))\n",
        "    \n",
        "\n",
        "# build model\n",
        "G = Generator().to(device)\n",
        "D = Discriminator().to(device)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oibE4-xq9BWy"
      },
      "source": [
        "# define loss\n",
        "criterion = nn.BCELoss() \n",
        "z_dim = 100\n",
        "bs = 100\n",
        "\n",
        "\n",
        "# optimizer\n",
        "lr = 0.0001 \n",
        "G_optimizer = torch.optim.Adam(G.parameters(), lr = lr)\n",
        "D_optimizer = torch.optim.Adam(D.parameters(), lr = lr)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yYJypw4w8xu7"
      },
      "source": [
        "# MNIST Dataset\n",
        "transform = transforms.Compose([\n",
        "    transforms.ToTensor(),\n",
        "    transforms.Normalize(mean=(0.5), std=(0.5))])\n",
        "\n",
        "train_dataset = MNIST(root='./mnist_data/', train=True, transform=transform, download=True)\n",
        "\n",
        "# Data Loader (Input Pipeline)\n",
        "train_loader = torch.utils.data.DataLoader(dataset=train_dataset, batch_size=bs, shuffle=True)\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rhCrSbKb-l6o"
      },
      "source": [
        "### some explainatory code for scatter_ function\n",
        "test_tensor = torch.zeros(5, 10)\n",
        "print('Zero tensor:')\n",
        "print(test_tensor)\n",
        "test_labels = torch.randint(low=0, high=10, size=(5,1))\n",
        "print('Labels:')\n",
        "print(test_labels)\n",
        "test_tensor.scatter_(1, test_labels,1)\n",
        "print('Scatter labels to tensor:')\n",
        "print(test_tensor)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "EuVC3m9G9C3j"
      },
      "source": [
        "def D_train(x, labs):\n",
        "    #-------------- Function of the discriminator training -------------------#\n",
        "    D.zero_grad()\n",
        "\n",
        "    # train discriminator on real data -- assign high score (1)\n",
        "    #*** make the labels (x_label_real) for real data samples -- use correct labels ***\n",
        "    x_real, y_real = x.view(-1, 28*28), torch.ones(bs, 1)\n",
        "    x_real, x_label_real, y_real = Variable(x_real.to(device)), Variable(x_label_real.to(device)), Variable(y_real.to(device))\n",
        "\n",
        "\n",
        "    D_output = D(x_real, x_label_real)\n",
        "    D_real_loss = criterion(D_output, y_real)\n",
        "    D_real_score = D_output\n",
        "\n",
        "    # train discriminator on fake data -- assign low score (0)\n",
        "    # sample vector and produce generator output\n",
        "\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "\n",
        "    #*** make the labels (z_label) for fake data samples -- use random labels ***\n",
        "\n",
        "    x_fake, y_fake = G(z, z_label), Variable(torch.zeros(bs, 1).to(device))\n",
        "\n",
        "    D_output = D(x_fake, z_label)\n",
        "    D_fake_loss = criterion(D_output, y_fake)\n",
        "\n",
        "    # combine the losses\n",
        "    D_loss = D_real_loss + D_fake_loss\n",
        "\n",
        "    # model update \n",
        "    D_loss.backward()\n",
        "    D_optimizer.step()\n",
        "\n",
        "        \n",
        "    return  D_loss.data.item()\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0wdYzttu8ybC"
      },
      "source": [
        "def G_train(x):\n",
        "    #-------------- Function of the generator training -------------------#\n",
        "    G.zero_grad()\n",
        "\n",
        "    # sample vector and produce generator output\n",
        "    z = Variable(torch.randn(bs, z_dim).to(device))\n",
        "    #*** make the labels (z_label) for fake data samples -- use random labels ***\n",
        "\n",
        "    G_output = G(z, z_label)\n",
        "\n",
        "    # obtain scores from D for the generated data\n",
        "    D_output = D(G_output, z_label)\n",
        "\n",
        "    # train generator to \"fool\" discriminator\n",
        "    y = Variable(torch.ones(bs, 1).to(device))\n",
        "    G_loss = criterion(D_output, y)\n",
        "\n",
        "    # model update \n",
        "    G_loss.backward()\n",
        "    G_optimizer.step()\n",
        "        \n",
        "    return G_loss.data.item()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fWoIQBns9HQT"
      },
      "source": [
        "n_epoch = 200 # about 40 minutes\n",
        "groups = {'Loss': ['D_Loss', 'G_Loss']}\n",
        "liveloss = PlotLosses(groups=groups)\n",
        "\n",
        "for epoch in range(1, n_epoch+1):  \n",
        "  D_losses, G_losses = [], []\n",
        "  logs = {}\n",
        "  for batch_idx, (x, labs) in enumerate(train_loader):\n",
        "    logs['D_Loss'] = D_train(x, labs)\n",
        "    logs['G_Loss'] = G_train(x)\n",
        "  liveloss.update(logs)\n",
        "  liveloss.draw()\n",
        "\n",
        "  # save every 20th epochs\n",
        "  if(np.mod(epoch, 20) == 0):\n",
        "    torch.save(G.state_dict(), \"./Generator_{:03d}.pth\".format(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9p7B3P8QLD20"
      },
      "source": [
        "epoch = 200\n",
        "G.load_state_dict(torch.load(\"./Generator_{:03d}.pth\".format(epoch)))\n",
        "\n",
        "\n",
        "with torch.no_grad():\n",
        "    test_z = Variable(torch.randn(100, z_dim).to(device))\n",
        "    test_z_label = torch.zeros(100, 10)\n",
        "    z_labels = torch.LongTensor([i for i in range(10) for _ in range(10)])\n",
        "    test_z_label.scatter_(1, z_labels.view(100, 1), 1)  \n",
        "    generated = G(test_z, Variable(test_z_label.to(device)))\n",
        "\n",
        "    # save_image(generated.view(generated.size(0), 1, 28, 28), './sample_' + '.png')\n",
        "fig, axarr = plt.subplots(10, 10, figsize=(12, 12))\n",
        "for ax, img in zip(axarr.flatten(), generated.view(generated.size(0), 28, 28).cpu()):\n",
        "  ax.imshow(img, cmap=\"gray\")\n",
        "plt.title('Epoch = {:03d}'.format(epoch))"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}