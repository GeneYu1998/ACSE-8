{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "name": "Morning_Session_4_Transfer_Learning_Exercise.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "display_name": "Python [default]",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.6.5"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "LL3vQPYkhzOy"
      },
      "source": [
        "!pip install pycm livelossplot\n",
        "%pylab inline"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "MXJ6R5CBhzPQ"
      },
      "source": [
        "#### A few imports before we get started"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5-tUzUV2hzPU"
      },
      "source": [
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.model_selection import StratifiedShuffleSplit\n",
        "\n",
        "from livelossplot import PlotLosses\n",
        "from pycm import *\n",
        "\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import TensorDataset, DataLoader\n",
        "import torchvision.transforms as transforms\n",
        "from torchvision.datasets import MNIST\n",
        "\n",
        "\n",
        "def set_seed(seed):\n",
        "    \"\"\"\n",
        "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
        "    \"\"\"\n",
        "    random.seed(seed)\n",
        "    np.random.seed(seed)\n",
        "    torch.manual_seed(seed)\n",
        "    torch.cuda.manual_seed_all(seed)\n",
        "\n",
        "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
        "    torch.backends.cudnn.enabled   = False\n",
        "\n",
        "    return True\n",
        "\n",
        "device = 'cpu'\n",
        "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
        "    print(\"Cuda installed! Running on GPU!\")\n",
        "    device = 'cuda'\n",
        "else:\n",
        "    print(\"No GPU available!\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "6tLRNHc8GOfR"
      },
      "source": [
        "### Mounting the google drive for later storage"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dg3oP6GHGOsX"
      },
      "source": [
        "from google.colab import drive\n",
        "drive.mount('/content/gdrive/')"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uRz54s_5GnMn"
      },
      "source": [
        "# Morning Session 4 pt II: Transfer Learning"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ssIYXFIjGn7A"
      },
      "source": [
        "We will now explore one of the arguably most useful practises when dealing with small-datasets and wanting to create a powerful classifier - transfer learning.\n",
        "Instead of training a network from randomly initialised weights, we start from a network with weights trained in a different domain and fine-tune it to a different source task.  \n",
        "\n",
        "The basic principle behind is to leverage features learned on very large datasets and recycle them to perform tasks on smaller datasets.  \n",
        "\n",
        "To be able to apply transfer learning effectively, the data distribution of the data that a very powerful model was trained on should follow a similar distribution as the smaller dataset that we are trying to apply transfer learning to.    \n",
        "\n",
        "For example:  \n",
        "_We want to create a new classifier for cats and dogs given only a small set of say 100 training images of each category._\n",
        "\n",
        "Very deep neural networks that have been trained on ImageNet or CIFAR have similar categories in their dataset, say horses and maybe cows and many more categories of natural images.  \n",
        "The intuition is that since we've already learned a rich set of features on ImageNet, we can simply use a deep network as a feature extractor and only retrain the final layer of the networks to perform well at our task. So let's work our way towards transfer learning.\n",
        "\n",
        "\n",
        "In summary, transfer learning can be a powerful tool for:\n",
        "- Preventing poor training from small-datasets\n",
        "- Reducing training time for similar tasks\n",
        "\n",
        "### Exercise 1: Inspecting the features of pre-trained deep neural networks\n",
        "\n",
        "Pytorch provides users with a rich set of pre-trained neural network architectures. These have mostly been pre-trained on imagenet.   \n",
        "[```torchvision.models```](https://pytorch.org/vision/stable/models.html) provides us with an interface to these pretrained deep neural networks.\n",
        "\n",
        "- Load a pretrained [AlexNet](https://arxiv.org/abs/1404.5997) model from ```torchvision.models``` ([Source Code](https://pytorch.org/vision/stable/_modules/torchvision/models/alexnet.html) for AlexNet in Pytorch)\n",
        "- Obtain the weight kernels of the first layer and display them (11x11 kernels shown as a matplotlib graph)\n",
        "- Remembering the earlier exercise on traditional computer vision kernels and edge detection, how could these come in handy when learning on new data?\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "gEgKXhsfa03b"
      },
      "source": [
        "from torchvision import models\n",
        "\n",
        "alexnet = #### code here ####\n",
        "print(alexnet)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "oLN_0LtMbOd8"
      },
      "source": [
        "first_layer = #### code here ####\n",
        "weights = #### code here ####\n",
        "print(first_layer)\n",
        "\n",
        "\n",
        "# Normalisation for plotting because imshow does like negative values\n",
        "min_w, max_w =  weights.min(), weights.max()\n",
        "weights -= min_w\n",
        "weights /= (max_w-min_w)\n",
        "\n",
        "fig, axarr = plt.subplots(8, 8, figsize=(12, 12))\n",
        "axarr = axarr.flatten()\n",
        "for ax, kernel in zip(axarr, weights.numpy()):\n",
        "  ax.imshow(np.swapaxes(kernel, 0, 2))"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "y39SqwzLekvw"
      },
      "source": [
        "### Exercise 2: Transfer learning from ImageNet to Bees and Ants\n",
        "\n",
        "In the previous exercise we've investigated what some features of a very deep pre-trained network look like and learned about transfer learning. Let's try it out! We will try to apply transfer learning to a small dataset containing images of bees and ants by training on top of networks previously trained on ImageNet.\n",
        "\n",
        "ImageNet is arguably the most popular dataset for benchmarking classification models. It contains around 14 million annotated natural images spread over 22 thousand categories. Images are of size 3 x 224 x 224, with normalised means and stds of [0.485, 0.456, 0.406] and [0.229, 0.224, 0.225]. In transfer learning is common practice to use the means and standard deviations of the data used for pretraining to normalise the new dataset. Note that the most popular networks (VGG, ResNet, AlexNet, etc..) have been design to take as input 3 x 224 x 224 images to accomodate for ImageNet.\n",
        "\n",
        "<p style=\"text-align:center;\"><img src=\"https://paperswithcode.com/media/datasets/ImageNet-0000000008-f2e87edd_Y0fT5zg.jpg\" alt=\"drawing\" width=\"500\"/>\n",
        "</p>\n",
        "\n",
        "Adapted from [here](https://pytorch.org/tutorials/beginner/transfer_learning_tutorial.html)\n",
        "\n",
        "Perform the following tasks:\n",
        "\n",
        "0. Adapt the training, validation and evaluation functions to the appropriate input size\n",
        "1. [Download](https://download.pytorch.org/tutorial/hymenoptera_data.zip) the dataset into your current directory (you can do it manually, our use the code is provided below)\n",
        "2. Investigate and visualize a few examples of the dataset. What pre-processing is required for this dataset?\n",
        "3. Instantiate an untrained ResNet18 from [```torchvision.models```](https://pytorch.org/vision/stable/models.html) and make the necessary adaptations to our task in hands.\n",
        "4. Train the newly initialised ResNet from scratch. What do you notice?\n",
        "5. Now instantiate the pre-trained ReseNet18 by passing the argument ``pretrained=True`` and perform fine-tuning using a smaller learning rate\n",
        "6. Use the provided ``set_parameters_requires_grad`` and ``get_params_to_update`` functions to repeat the step above freezing optimisation for all layers except the final classifying layer.\n",
        "7. Finally, train a ResNet on MNIST from scratch and use those weights to repeat step 6. Does this work?\n",
        "\n",
        "  \n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "zcRkTyYxxIA9"
      },
      "source": [
        "### 2.0 Adapting training, validation and evaluation functions to our problem size"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VKoKWyIgwZQ2"
      },
      "source": [
        "def train(model, optimizer, criterion, data_loader):\n",
        "    model.train()\n",
        "    train_loss, train_accuracy = 0, 0\n",
        "    for X, y in data_loader:\n",
        "        X, y = X.to(device), y.to(device)\n",
        "        optimizer.zero_grad()\n",
        "        a2 = model(X.view(#### code here ####))\n",
        "        loss = criterion(a2, y)\n",
        "        loss.backward()\n",
        "        train_loss += loss*X.size(0)\n",
        "        y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
        "        optimizer.step()  \n",
        "        \n",
        "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def validate(model, criterion, data_loader):\n",
        "    model.eval()\n",
        "    validation_loss, validation_accuracy = 0., 0.\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            a2 = model(X.view(#### code here ####))\n",
        "            loss = criterion(a2, y)\n",
        "            validation_loss += loss*X.size(0)\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
        "            \n",
        "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
        "  \n",
        "def evaluate(model, data_loader):\n",
        "    model.eval()\n",
        "    ys, y_preds = [], []\n",
        "    for X, y in data_loader:\n",
        "        with torch.no_grad():\n",
        "            X, y = X.to(device), y.to(device)\n",
        "            a2 = model(X.view(#### code here ####))\n",
        "            y_pred = F.log_softmax(a2, dim=1).max(1)[1]\n",
        "            ys.append(y.cpu().numpy())\n",
        "            y_preds.append(y_pred.cpu().numpy())\n",
        "            \n",
        "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-dAUDSUqtp9r"
      },
      "source": [
        "### 2.1 Loading and Visualising the Data"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "bieaCiLBUnCG"
      },
      "source": [
        "!wget -nc https://download.pytorch.org/tutorial/hymenoptera_data.zip && unzip -oq hymenoptera_data.zip"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "TeHS9U038ms_"
      },
      "source": [
        "seed = 42\n",
        "lr = 1e-2\n",
        "momentum = 0.9\n",
        "batch_size = 64\n",
        "test_batch_size = 1000\n",
        "n_epochs = 30"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ClWBbBL1iNke"
      },
      "source": [
        "from torchvision import datasets, transforms, models\n",
        "\n",
        "transform = transforms.Compose([\n",
        "        #### code here ####\n",
        "    ])\n",
        "\n",
        "train_ds = #### code here ####\n",
        "test_ds = #### code here ####\n",
        "\n",
        "print(train_ds)\n",
        "print(train_ds.classes)\n",
        "print(train_ds.class_to_idx)\n",
        "print(train_ds[0]) # an example of calling  __getitem__, which is what the dataloader does\n",
        "print(train_ds.samples[0]) # get image path inside samples\n",
        "print(\"\\n\\n\")\n",
        "\n",
        "# Get mean and std\n",
        "tmp_loader = DataLoader(train_ds, batch_size=1, num_workers=0)\n",
        "data = next(iter(tmp_loader))\n",
        "mean = [torch.mean(data[0][0][i].flatten()).item() for i in range(3)]\n",
        "std = [torch.std(data[0][0][i].flatten()).item() for i in range(3)]\n",
        "print(mean, std)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6rg29zjqkb1l"
      },
      "source": [
        "def show_batch(dataset, nr=4, nc=4):\n",
        "  fig, axarr = plt.subplots(nr, nc, figsize=(10, 10))\n",
        "  for i in range(nr):\n",
        "      for j in range(nc):\n",
        "          idx = random.randint(0, len(train_ds))\n",
        "          sample, target = train_ds[idx]\n",
        "          try:\n",
        "            axarr[i][j].imshow(sample) # if PIL\n",
        "          except:\n",
        "            axarr[i][j].imshow(sample.permute(1,2,0)) # if tensor of shape CHW\n",
        "          target_name = train_ds.classes[target]\n",
        "          axarr[i][j].set_title(\"%s (%i)\"%(target_name, target))\n",
        "\n",
        "  fig.tight_layout(pad=1.5)\n",
        "  plt.show()"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "-3IffdzCmaTQ"
      },
      "source": [
        "show_batch(train_ds, 5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4DLYvyI3mlYj"
      },
      "source": [
        "# Fix image sizes with transforms\n",
        "train_transform = transforms.Compose([\n",
        "        #### code here ####\n",
        "        transforms.ToTensor()\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        #### code here ####\n",
        "        transforms.ToTensor(),\n",
        "    ])\n",
        "\n",
        "train_ds = datasets.ImageFolder(\"./hymenoptera_data/train\", transform=train_transform)\n",
        "test_ds = datasets.ImageFolder(\"./hymenoptera_data/val\", transform=test_transform)\n",
        "\n",
        "show_batch(train_ds, 5, 5)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "xSHLIl2Vjir6"
      },
      "source": [
        "# Finally add normalisation to transforms\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        #### code here ####\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        #### code here ####\n",
        "    ])\n",
        "\n",
        "train_ds = datasets.ImageFolder(\"./hymenoptera_data/train\", transform=train_transform)\n",
        "test_ds = datasets.ImageFolder(\"./hymenoptera_data/val\", transform=test_transform)\n",
        "\n",
        "# Create dataloader\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "38oqk6JAgcAH"
      },
      "source": [
        "### 2.2 Training a newly initialized Resnet18\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "YUWuzybrUnCJ"
      },
      "source": [
        "set_seed(seed)\n",
        "\n",
        "model = models.resnet18().to(device)\n",
        "print(model)\n",
        "#### code here ####\n",
        "\n",
        "# optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "# criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "# liveloss = PlotLosses()\n",
        "# for epoch in range(n_epochs):\n",
        "#     logs = {}\n",
        "#     train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "#     logs['' + 'log loss'] = train_loss.item()\n",
        "#     logs['' + 'accuracy'] = train_accuracy.item()\n",
        "#     liveloss.update(logs)\n",
        "#     liveloss.draw()\n",
        "#     logs['val_' + 'log loss'] = 0.\n",
        "#     logs['val_' + 'accuracy'] = 0.\n",
        "    \n",
        "# test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
        "# print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
        "# print(\"\")\n",
        "\n",
        "# model_save_name = 'resnet18_bees_and_ants_classifier_full_training_set_baseline.pt'\n",
        "# path = F\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
        "# torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "P_-rX8y8xShf"
      },
      "source": [
        "What is happening to the model? Why?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "xRTvtY_wzYS5"
      },
      "source": [
        "### 2.3 Finetuning a pre-trained Resenet"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Dw6iEkZDzcrX"
      },
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        #### add normalisation here ####\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        #### add normalisation here ####\n",
        "    ])\n",
        "\n",
        "train_ds = datasets.ImageFolder(\"./hymenoptera_data/train\", transform=train_transform)\n",
        "test_ds = datasets.ImageFolder(\"./hymenoptera_data/val\", transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "model = #### load pre-trained resnet here ####\n",
        "model.fc = nn.Linear(model.fc.in_features, 2).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr= ### what should our learning rate be? #### , momentum=momentum)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "for epoch in range(n_epochs):\n",
        "    logs = {}\n",
        "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    logs['' + 'log loss'] = train_loss.item()\n",
        "    logs['' + 'accuracy'] = train_accuracy.item()\n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()\n",
        "    logs['val_' + 'log loss'] = 0.\n",
        "    logs['val_' + 'accuracy'] = 0.\n",
        "    \n",
        "test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
        "print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
        "print(\"\")\n",
        "\n",
        "model_save_name = 'resnet18_bees_and_ants_classifier_full_training_set_imagenet_finetune.pt'\n",
        "path = F\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "EkNygrxGUnCK"
      },
      "source": [
        "### 2.4 Pre-trained Resenet as a Feature Extraction Tool"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "j-e4S1a6yV-d"
      },
      "source": [
        "def set_parameter_requires_grad(model, requires_grad=False):\n",
        "    \"\"\"https://pytorch.org/tutorials/beginner/finetuning_torchvision_models_tutorial.html\"\"\"\n",
        "    for param in model.parameters():\n",
        "        param.requires_grad = requires_grad\n",
        "    return None\n",
        "\n",
        "def get_params_to_update(model):\n",
        "    \"\"\" Returns list of model parameters that have required_grad=True\"\"\"\n",
        "    params_to_update = []\n",
        "    for name,param in model.named_parameters():\n",
        "        if param.requires_grad == True:\n",
        "            params_to_update.append(param)\n",
        "    return params_to_update"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UB0F3hy5UnCL"
      },
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize([0.485, 0.456, 0.406], [0.229, 0.224, 0.225])\n",
        "    ])\n",
        "\n",
        "train_ds = datasets.ImageFolder(\"./hymenoptera_data/train\", transform=train_transform)\n",
        "test_ds = datasets.ImageFolder(\"./hymenoptera_data/val\", transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "model = models.resnet18(pretrained=True).to(device)\n",
        "### disable requires_grad for model parameters here ### \n",
        "model.fc = nn.Linear(model.fc.in_features, 2).to(device)  # newly initialised layers automatically have requires_grad=True\n",
        "\n",
        "optimizer = torch.optim.SGD(get_params_to_update(model), lr=0.1*lr, momentum=momentum)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "for epoch in range(n_epochs):\n",
        "    logs = {}\n",
        "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    logs['' + 'log loss'] = train_loss.item()\n",
        "    logs['' + 'accuracy'] = train_accuracy.item()\n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()\n",
        "    logs['val_' + 'log loss'] = 0.\n",
        "    logs['val_' + 'accuracy'] = 0.\n",
        "    \n",
        "test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
        "print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
        "print(\"\")\n",
        "\n",
        "model_save_name = 'resnet18_bees_and_ants_classifier_full_training_set_imagenet_feature_extract.pt'\n",
        "path = F\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-qWGFNyJ-u2F"
      },
      "source": [
        "If feature extraction can provide sufficiently good accuracy, we can significantly cut in traning time, particularly when the network is very deep and input images are large.\n",
        "\n",
        "Fine tuning our model parts from the idea that the model starts from a point already close to the optimisation minimum; and that all we are doing is getting closer to that minimum. Feature extraction makes use of the exact features that are used to classified another dataset, only really tuning the final classifying layer."
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "N5DmQlc_ebYf"
      },
      "source": [
        "<img src=\"https://pbs.twimg.com/media/Ev-f6AaU8AgMeRd.jpg\" alt=\"drawing\" width=\"600\"/>"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "-aGsi18_UnCL"
      },
      "source": [
        "### 2.5 What if pretrained on MNIST instead?"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "GvQ8SKahEfqV"
      },
      "source": [
        "####  Training a Resnet on MNIST from scratch"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "PVWsSuo-UnCM"
      },
      "source": [
        "train_transform = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,)),  \n",
        "        transforms.Lambda(lambda x: x.expand(3, 224, 224)), # expand to 3 channels               \n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(224),\n",
        "        transforms.ToTensor(),\n",
        "        transforms.Normalize((0.1307,), (0.3081,)),\n",
        "        transforms.Lambda(lambda x: x.expand(3, 224, 224)), # expand to 3 channels      \n",
        "    ])\n",
        "\n",
        "mnist_train = MNIST(\"./\", download=True, train=True, transform=train_transform)\n",
        "mnist_test = MNIST(\"./\", download=True, train=False, transform=test_transform)\n",
        "\n",
        "# print(mnist_train[0][0].shape)\n",
        "# plt.imshow(mnist_train[0][0].permute(1,2,0))\n",
        "# plt.show()\n",
        "\n",
        "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
        "test_loader = DataLoader(mnist_test, batch_size=batch_size, shuffle=False, num_workers=4)\n",
        "\n",
        "model = models.resnet18().to(device)\n",
        "#### modify last layer here ####\n",
        "\n",
        "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "feeling_lazy = True\n",
        "\n",
        "if feeling_lazy:\n",
        "  !gdown --id 1tOeWpr3jrKgtFu2qx1_4orLx_bwe-467\n",
        "  path = F\"./resnet18_mnist_trained.pt\" \n",
        "  model.load_state_dict(torch.load(path))\n",
        "\n",
        "else:\n",
        "  ### ~ 7 min per epoch here ###\n",
        "  liveloss = PlotLosses()\n",
        "  for epoch in range(n_epochs):\n",
        "      logs = {}\n",
        "      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "      logs['' + 'log loss'] = train_loss.item()\n",
        "      logs['' + 'accuracy'] = train_accuracy.item()\n",
        "      liveloss.update(logs)\n",
        "      liveloss.draw()\n",
        "      logs['val_' + 'log loss'] = 0.\n",
        "      logs['val_' + 'accuracy'] = 0.\n",
        "\n",
        "model_save_name = 'resnet18_mnist_classifier_full_training_set_baseline_.pt'\n",
        "path = F\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
        "print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
        "print(\"\")"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j38pm3TBExK6"
      },
      "source": [
        "### 2.6 Feature Extraction on the ResNet pretrained on MNIST\n"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "15DVykO4kaw_"
      },
      "source": [
        "set_seed(seed)\n",
        "\n",
        "train_transform = transforms.Compose([\n",
        "        transforms.RandomResizedCrop(224),\n",
        "        transforms.RandomHorizontalFlip(),\n",
        "        transforms.ToTensor(),\n",
        "        #### add normalisation here ####,\n",
        "    ])\n",
        "test_transform = transforms.Compose([\n",
        "        transforms.Resize(256),\n",
        "        transforms.CenterCrop(224),\n",
        "        transforms.ToTensor(),\n",
        "        #### add normalisation here ####,\n",
        "    ])\n",
        "\n",
        "train_ds = datasets.ImageFolder(\"./hymenoptera_data/train\", transform=train_transform)\n",
        "test_ds = datasets.ImageFolder(\"./hymenoptera_data/val\", transform=test_transform)\n",
        "\n",
        "train_loader = DataLoader(train_ds, batch_size=batch_size, shuffle=True, num_workers=0)\n",
        "test_loader = DataLoader(test_ds, batch_size=batch_size, shuffle=False, num_workers=0)\n",
        "\n",
        "model = models.resnet18().to(device)\n",
        "model.fc = nn.Linear(model.fc.in_features, 10).to(device)\n",
        "path = F\"./resnet18_mnist_trained.pt\" \n",
        "model.load_state_dict(torch.load(path))\n",
        "model.fc = nn.Linear(model.fc.in_features, 2).to(device)\n",
        "\n",
        "optimizer = torch.optim.SGD(model.fc.parameters(), lr=0.1*lr, momentum=momentum)\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "\n",
        "liveloss = PlotLosses()\n",
        "for epoch in range(n_epochs):\n",
        "    logs = {}\n",
        "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
        "\n",
        "    logs['' + 'log loss'] = train_loss.item()\n",
        "    logs['' + 'accuracy'] = train_accuracy.item()\n",
        "    liveloss.update(logs)\n",
        "    liveloss.draw()\n",
        "    logs['val_' + 'log loss'] = 0.\n",
        "    logs['val_' + 'accuracy'] = 0.\n",
        "\n",
        "model_save_name = 'resnet18_bees_and_antes_classifier_full_training_set_mnist_transfer.pt'\n",
        "path = F\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
        "torch.save(model.state_dict(), path)\n",
        "\n",
        "\n",
        "test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
        "print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
        "print(\"\")\n",
        "\n"
      ],
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wVDOioLU_32t"
      },
      "source": [
        "What does this tell us?"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yeBc30RWrrnT"
      },
      "source": [
        ""
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}