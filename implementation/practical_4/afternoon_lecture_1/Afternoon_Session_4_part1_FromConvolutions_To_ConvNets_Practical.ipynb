{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "03n7uqrfZRwf"
   },
   "source": [
    "#### Notebook modified from the original version by `Lukas Mosser` and `Navjot Kukreja`"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "LL3vQPYkhzOy",
    "outputId": "d5ce07d7-ebef-41f5-f5fc-7742486f59fd"
   },
   "outputs": [],
   "source": [
    "!pip install pycm livelossplot\n",
    "%pylab inline"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "En9dBOn0hzPL"
   },
   "source": [
    "## ACSE 8 Session 4:\n",
    "# From Convolutions to ConvNets\n",
    "\n",
    "###Objectives of this session:\n",
    "Thursday 6 May 13:00-16:00h:\n",
    "- Very quick overview of convolutions in traditional Computer Vision with examples of... cats.\n",
    "- Torch layer operations simple examples with... cats.\n",
    "- Torch Convolutional layers.\n",
    "- Implementation of a network similar to LeNet5.\n",
    "- Train our LeNet5-like network on MNIST\n",
    "Friday 7 May 13:00h-16:00h\n",
    "- Train MNIST again using data augmentation\n",
    "- Transfer Learning: bees & ants (***Debbie***)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "F_B7byqdcKgd"
   },
   "source": [
    "On practical 2, we learned how to **train a feed-forward network**.\n",
    "On practical 3, we learned how to **optimise for hyperparameters** with cross-validation.\n",
    "\n",
    "Today we will use these two techniques on **CNNs**.\n",
    "\n",
    "<img src=\"https://miro.medium.com/max/2340/1*Fw-ehcNBR9byHtho-Rxbtw.gif\" alt=\"network\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "MXJ6R5CBhzPQ"
   },
   "source": [
    "#### A few imports before we get started"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5-tUzUV2hzPU",
    "outputId": "3583e40a-451b-4b96-9d23-13e1867a8e11"
   },
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import StratifiedShuffleSplit\n",
    "\n",
    "from livelossplot import PlotLosses\n",
    "from pycm import *\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "import torchvision.transforms as transforms\n",
    "from torchvision.datasets import MNIST\n",
    "\n",
    "\n",
    "def set_seed(seed):\n",
    "    \"\"\"\n",
    "    Use this to set ALL the random seeds to a fixed value and take out any randomness from cuda kernels\n",
    "    \"\"\"\n",
    "    random.seed(seed)\n",
    "    np.random.seed(seed)\n",
    "    torch.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "\n",
    "    torch.backends.cudnn.benchmark = False  ##uses the inbuilt cudnn auto-tuner to find the fastest convolution algorithms. -\n",
    "    torch.backends.cudnn.enabled   = False\n",
    "\n",
    "    return True\n",
    "\n",
    "device = 'cpu'\n",
    "if torch.cuda.device_count() > 0 and torch.cuda.is_available():\n",
    "    print(\"Cuda installed! Running on GPU!\")\n",
    "    device = 'cuda'\n",
    "else:\n",
    "    print(\"No GPU available!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "6tLRNHc8GOfR"
   },
   "source": [
    "### Mounting the google drive for later storage"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "Dg3oP6GHGOsX",
    "outputId": "84b39509-3792-414f-a9b5-29b349d73181"
   },
   "outputs": [],
   "source": [
    "from google.colab import drive\n",
    "drive.mount('/content/gdrive/')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "xMI78ZcpeAm3"
   },
   "source": [
    "# Important concepts from previous sessions revisited:\n",
    "\n",
    "- **Recap 1** `StratifiedShuffleSplit` to split our training dataset into training and validation for k-fold validation:\n",
    "\n",
    "  - compute indices using `StratifiedShuffleSplit`\n",
    "  - standardise data\n",
    "  - create normalised training, validation, and test datasets as TensorDatasets"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Jk1EucZ_epf4"
   },
   "outputs": [],
   "source": [
    "shuffler = StratifiedShuffleSplit(n_splits=1, test_size=0.1, random_state=42).split(mnist_train.train_data, mnist_train.train_labels)\n",
    "indices = [(train_idx, validation_idx) for train_idx, validation_idx in shuffler][0]\n",
    "\n",
    "def apply_standardization(X):\n",
    "  X /= 255.\n",
    "  X -= 0.1307\n",
    "  X /= 0.3081\n",
    "  return X\n",
    "\n",
    "X_train, y_train = apply_standardization(mnist_train.train_data[indices[0]].float()), mnist_train.train_labels[indices[0]]\n",
    "X_val, y_val = apply_standardization(mnist_train.train_data[indices[1]].float()), mnist_train.train_labels[indices[1]]\n",
    "X_test, y_test =  apply_standardization(mnist_test.test_data.float()), mnist_test.test_labels\n",
    "\n",
    "mnist_train = TensorDataset(X_train, y_train.long())\n",
    "mnist_validate = TensorDataset(X_val, y_val.long())\n",
    "mnist_test = TensorDataset(X_test, y_test.long())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "chhItweAflo8"
   },
   "source": [
    "<img src=\"https://scikit-learn.org/stable/_images/grid_search_cross_validation.png\" alt=\"network\" width=\"500\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "e0gaWjLKgMBu"
   },
   "source": [
    "<br>\n",
    "\n",
    "- **Recap 2** livelossplot to visualise training evolution\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/stared/livelossplot/master/livelossplot.gif\" alt=\"network\" width=\"800\"/>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "CEwibQeWjYQC"
   },
   "source": [
    "## Computer Vision - Convolutions as Feature Detectors\n",
    "\n",
    "In the following exercise we'll do some classical computer vision before moving to convolutional networks.\n",
    "We will use the [Sobel-filter](https://en.wikipedia.org/wiki/Sobel_operator), a classical convolution operator.\n",
    "\n",
    "### Task 1:\n",
    "Implement the Sobel Filter $G_x$ (according to its wiki definition, see link above) as a simple 2D convolution operation.\n",
    "\n",
    "- First instantiate a [`nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html) object with a single 3x3 kernel, padding=1, taking in a single image channel and outputting one channel.  \n",
    "- Then modify the weight matrix to reflect the sobel filter."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "EwYSi4s8jYcj",
    "outputId": "8c75227a-c31c-4f0d-b645-79a523c96952"
   },
   "outputs": [],
   "source": [
    "from PIL import Image  # PIL is hte Python Imaging Library\n",
    "import requests        # library that provides an easy way to make http requests\n",
    "from io import BytesIO # let's us read raw bites as a file\n",
    "\n",
    "url = \"https://cataas.com/cat\" # cat as a service!\n",
    "response = requests.get(url)   # requests a cat\n",
    "img = np.array(Image.open(BytesIO(response.content)).convert('L')).astype(float) # BytesIO tells python to read it as a file (and .content extracts only the image bytes)\n",
    "plt.imshow(img, cmap=\"gray\")   # matplotlib likes numpy arrays"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "3B-LEXgYjY1T"
   },
   "source": [
    "### `code along` Implement the Sobel Filter $G_x$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 356
    },
    "id": "UhsnPUiCjY-p",
    "outputId": "49e08fbe-b046-4cf1-ff6c-902fcceb6298"
   },
   "outputs": [],
   "source": [
    "# define sobel as an instance of an nn.Conv2d class.\n",
    "# print the size of the filter\n",
    "# define a filter as a torch.Tensor with the right coefficients\n",
    "# assign filter values to the sobel object\n",
    "# load the cat image as a tensor\n",
    "# filter the cat image\n",
    "# plot the Sobel-filtered version of the cat\n",
    "## detach() is necessary to detach filtered_cat from the computational graph before it can be converted to a numpy array for plotting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "0CK1ONK9jZJG"
   },
   "source": [
    "## Some useful Pytorch Layers\n",
    "\n",
    "- [`nn.Conv2d`](https://pytorch.org/docs/stable/generated/torch.nn.Conv2d.html): Convolutional layers are parameterized by their kernel-weights and biases and are often used to reduce the spatial dimensionality.\n",
    "- [`nn.ConvTranspose2d`](https://pytorch.org/docs/stable/generated/torch.nn.ConvTranspose2d.html): Transposed convolutions (not deconvolutions!); similar to convolutions, but normally used to upsample (increase the spatial dimensionality). [Interesting blog discussing problems with tranposed convolutions](https://distill.pub/2016/deconv-checkerboard/)\n",
    "- [`nn.UpsamplingBilinear2d`](https://pytorch.org/docs/stable/generated/torch.nn.UpsamplingBilinear2d.html) for upsampling (also check nearest neighbor upsampling, `nn.Upsample`)\n",
    "- [`nn.MaxPool2d`](https://pytorch.org/docs/stable/generated/torch.nn.MaxPool2d.html): Pooling layers summarize spatial information (also check  `nn.AvgPool2d`)\n",
    "- [`nn.Dropout2d`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout2d.html): Also exists in two (and more) dimensions: Can be use to regularise training of deep networks\n",
    "- Batch normalisation: Shift and center the distribution of the weights to a centered Gaussian distribution by keeping a running average of mini-batch properties. Introduced in [this paper](https://arxiv.org/abs/1502.03167). Originally, it was thought that doing batch normalisation would reduce the internal covariate shift and accelerate training, but a [later paper](https://arxiv.org/abs/1805.11604) questioned if that was the real reason why it was working so well. It seems to help learning in very deep convolutional neural networks, but it is not really well understood why this is the case.\n",
    "\n",
    "The pytorch documentation is extremely well organised and I highly recommend you use it to your own advantage."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 917
    },
    "id": "vcKRCL3ojZT_",
    "outputId": "f085c1b7-50d5-4baf-d63b-f7b6e8a6908b"
   },
   "outputs": [],
   "source": [
    "convolution = nn.Conv2d(1, 1, kernel_size=5, padding=2, stride=1)\n",
    "transposed_convolution = nn.ConvTranspose2d(1, 1, kernel_size=4, stride=2)\n",
    "upsampling = nn.UpsamplingBilinear2d(scale_factor=2)\n",
    "pool = nn.MaxPool2d(kernel_size=2, stride=2)\n",
    "dropout = nn.Dropout(0.5)\n",
    "#dropout = nn.Dropout2d(0.5)\n",
    "batchnorm = nn.BatchNorm2d(1) ##1 corresponds to the number of output channels in the convolutional layer\n",
    "\n",
    "plt.imshow(img)\n",
    "\n",
    "fig, axarr = plt.subplots(2, 3, figsize=(24, 12))\n",
    "for ax, op, name in zip(axarr.flatten(), [convolution, transposed_convolution, upsampling, pool, dropout, batchnorm], [\"conv\", \"conv_transposed\", \"upsample\", \"pool\", \"dropout\", \"batchnorm\"]):\n",
    "  filtered = op(x)\n",
    "  im = ax.imshow(filtered[0, 0].detach().numpy())\n",
    "  ax.set_title(name, fontsize=18)\n",
    "  #fig.colorbar(im, ax=ax, fraction=0.03)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "tA4ostDxBmzX"
   },
   "source": [
    "### A clearer/simpler toy-example to understand [`nn.Dropout`](https://pytorch.org/docs/stable/generated/torch.nn.Dropout.html) layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "zzirX4S0Adrn",
    "outputId": "33dd9068-f2ce-41ea-91d8-3d4d14ffd593"
   },
   "outputs": [],
   "source": [
    "p = 0.1\n",
    "m = nn.Dropout(p=p)\n",
    "input = torch.randn(25, 25)*100000\n",
    "output = m(input)\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "im = plt.imshow(output.detach().numpy(), cmap='seismic')#, vmin=-0.1, vmax=0.1)\n",
    "plt.colorbar(im,fraction=0.044, pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "AyVRYmZ2KeiL"
   },
   "source": [
    "what does the value p do?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "wjo33WVTKQDA"
   },
   "source": [
    "### A clearer/simpler toy-example to understand [`nn.BatchNorm2d`](https://pytorch.org/docs/stable/generated/torch.nn.BatchNorm2d.html) layers:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 452
    },
    "id": "gkkKPrqpC3hs",
    "outputId": "42e4aed8-d396-4d4f-91f3-38a39b8ba548"
   },
   "outputs": [],
   "source": [
    "m = nn.BatchNorm2d(1)\n",
    "input = torch.randn(1,1,25, 25)*100000\n",
    "output = m(input)\n",
    "\n",
    "plt.figure(figsize = (8,8))\n",
    "im = plt.imshow(output[0,0].detach().numpy(), cmap='seismic')\n",
    "plt.colorbar(im,fraction=0.044, pad=0.1)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "JgQEvaEwsQr5"
   },
   "source": [
    "<br>\n",
    "\n",
    "### Before we start coding CNNs, let's make sure we know what we are doing:\n",
    "\n",
    "[CNN Explainer](https://poloclub.github.io/cnn-explainer/)\n",
    "\n",
    "<br>\n",
    "\n",
    "[interactive cool MNIST classifeir](https://www.cs.ryerson.ca/~aharley/vis/conv/flat.html)\n",
    "\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "FYn-cWg8jZcL"
   },
   "source": [
    "### Task 2: A simple Convolutional Network - LeNet-5 (almost)\n",
    "![](https://www.researchgate.net/profile/Vladimir_Golovko3/publication/313808170/figure/fig3/AS:552880910618630@1508828489678/Architecture-of-LeNet-5.png)\n",
    "\n",
    "We will now use the layer classes we just saw to implement a version of Yann LeCun's LeNet-5 (see figure above).\n",
    "\n",
    "\n",
    "- Here the network is shown to have input's of size 32x32, so we will tell our first convolutional layer to add some padding to our 28x28 MNIST images.  \n",
    "- All convolutional layers with trainable parameters should have:\n",
    "  - kernel-size=5\n",
    "  - stride 1\n",
    "  - padding 2.  \n",
    "- All MaxPool layers use a kernel size 2 and a stride value of 2.\n",
    "- Use ReLUs for all activations.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "X8Zfg2VHjZk-",
    "outputId": "fc09f838-0183-408c-f307-559aa1d1fde4"
   },
   "outputs": [],
   "source": [
    "class LeNet5(nn.Module):\n",
    "  def __init__(self):\n",
    "    super(LeNet5, self).__init__()\n",
    "    # define a 2D convolutional layer\n",
    "    # define a maxpool layer\n",
    "    # new 2D convolutional layer\n",
    "    # another maxpool layer\n",
    "    # first linear layer\n",
    "    # second linear layer\n",
    "    # final output layer\n",
    "    # activation function\n",
    "    \n",
    "  def forward(self, x):\n",
    "    # activate pass through the first layer\n",
    "    # activate pass through the second layer\n",
    "    # activate pass through the third layer\n",
    "    # activate pass through the fourth layer\n",
    "    # flatten (return a \"flattened\" view of the 2d tensor as inputs for the fully connected layer)\n",
    "    # activate pass through fifth layer\n",
    "    # activate pass through last layer\n",
    "    # return output\n",
    "  \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ytodnrWQEyhD"
   },
   "source": [
    "**Bonus**: On the original [paper](http://vision.stanford.edu/cs598_spring07/papers/Lecun98.pdf) there were a few important differences from what we just implemented. Can you name any?\n",
    "\n",
    "- No ReLUs but sigmoids and one weight and bias per pooling layer.\n",
    "- Not all filters in S2-C3 act on all layers on S2\n",
    "\n",
    "That's why we have an almost LeNet-5"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "y_UioFmvFIDw"
   },
   "source": [
    "### The MNIST Dataset - Hello World of Deep-Learning - Now with ConvNets!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "3K-yVuQvhzPs"
   },
   "outputs": [],
   "source": [
    "mnist_train = MNIST(\"./\", download=True, train=True)\n",
    "mnist_test = MNIST(\"./\", download=True, train=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "ZIKWFh11AK_Y"
   },
   "source": [
    "### `code along` Instantiate and create a ```StratifiedShuffleSplit``` using sklearn.\n",
    "1. Create a ```sklearn.model_selection.StratifiedShuffleSplit``` object with 1-split and a test-size of 10%.\n",
    "2. Get the training and validation indices from the shuffel-split "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "5zHKxYrY_15l",
    "outputId": "e1285af0-3680-433b-837a-07afb303b8a3"
   },
   "outputs": [],
   "source": [
    "# find indices to split the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "euZacTUtALq7"
   },
   "source": [
    "### `code along` Standardise and split the MNIST dataset\n",
    "The original mnist data is given in gray-scale values between 0 and 255.\n",
    "You will need to write a normalisation method that takes in a ```torch.Tensor``` and performs normalisation.\n",
    "The mean of MNIST is 0.1307 and it's standard deviation is 0.3081 (after division by 255)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "BY7_QOdPIDXm"
   },
   "outputs": [],
   "source": [
    "# define an standardisation function\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "C33RJWTM_12w",
    "outputId": "bc5f9bcf-9795-4bf1-89b2-c7a2a52baf5d"
   },
   "outputs": [],
   "source": [
    "# standardise the data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "RM9owG-yAMLv"
   },
   "source": [
    "### `code along` Instantiate a ```torch.utils.data.TensorDataset``` for training, validation and test data\n",
    "\n",
    "Remember that we use TensorDataset to be able to operate on the dataset without having to load it all in memory.\n",
    "\n",
    "And remember that torch likes all categorical data to be in a ```.long()``` format.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "9IjL4N-P_1zV"
   },
   "outputs": [],
   "source": [
    "# create the TensorDatasets containing mnist_train, mnist_validate, and mnist_test\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "LZ2qMRUGAEUA"
   },
   "source": [
    "Let's visualise an example of the images and check whether the data is normalised properly (compute .mean() and .std() on the training set.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 282
    },
    "id": "JVlMiRAmoh0O",
    "outputId": "d4876713-0221-4a6f-dc4d-342308535b6b"
   },
   "outputs": [],
   "source": [
    "plt.imshow(X_train[0], cmap = 'gray')\n",
    "print(X_train.mean(), X_train.std())"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "bcFPI8XKAOtl"
   },
   "source": [
    "### Provided Train, Validation and Evaluate Functions\n",
    "\n",
    "There is an error in these functions. Can you spot it?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "FRrehKxjhzQQ"
   },
   "outputs": [],
   "source": [
    "def train(model, optimizer, criterion, data_loader):\n",
    "    model.train()\n",
    "    train_loss, train_accuracy = 0, 0\n",
    "    for X, y in data_loader:\n",
    "        X, y = X.to(device), y.to(device)\n",
    "        optimizer.zero_grad()\n",
    "        output = model(X.view(-1, 28*28))\n",
    "        loss = criterion(output, y)\n",
    "        loss.backward()\n",
    "        train_loss += loss*X.size(0)\n",
    "        y_pred = F.log_softmax(output, dim=1).max(1)[1]\n",
    "        train_accuracy += accuracy_score(y.cpu().numpy(), y_pred.detach().cpu().numpy())*X.size(0)\n",
    "        optimizer.step()  \n",
    "        \n",
    "    return train_loss/len(data_loader.dataset), train_accuracy/len(data_loader.dataset)\n",
    "  \n",
    "def validate(model, criterion, data_loader):\n",
    "    model.eval()\n",
    "    validation_loss, validation_accuracy = 0., 0.\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X.view(-1, 28*28)) \n",
    "            loss = criterion(output, y)\n",
    "            validation_loss += loss*X.size(0)\n",
    "            y_pred = F.log_softmax(output, dim=1).max(1)[1]\n",
    "            validation_accuracy += accuracy_score(y.cpu().numpy(), y_pred.cpu().numpy())*X.size(0)\n",
    "            \n",
    "    return validation_loss/len(data_loader.dataset), validation_accuracy/len(data_loader.dataset)\n",
    "  \n",
    "def evaluate(model, data_loader):\n",
    "    model.eval()\n",
    "    ys, y_preds = [], []\n",
    "    for X, y in data_loader:\n",
    "        with torch.no_grad():\n",
    "            X, y = X.to(device), y.to(device)\n",
    "            output = model(X.view(-1, 28*28)) \n",
    "            y_pred = F.log_softmax(output, dim=1).max(1)[1]\n",
    "            ys.append(y.cpu().numpy())\n",
    "            y_preds.append(y_pred.cpu().numpy())\n",
    "            \n",
    "    return np.concatenate(y_preds, 0),  np.concatenate(ys, 0)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "i_pehihNAQ9E"
   },
   "source": [
    " ### Set the hyperparameters of your model\n",
    "- Seed: 42\n",
    "- learning rate: 1e-2\n",
    "- Optimizer: SGD\n",
    "- momentum: 0.9\n",
    "- Number of Epochs: 30\n",
    "- Batchsize: 64\n",
    "- Test Batch Size (no effect on training apart from time): 1000\n",
    "- Shuffle the training set every epoch: Yes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "Zvp3L6IGhzQj"
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "lr = 1e-2\n",
    "momentum = 0.5\n",
    "batch_size = 64\n",
    "test_batch_size = 1000\n",
    "n_epochs = 30"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "-QgnLf8fJ8nG"
   },
   "source": [
    "### Instantiate our model, optimizer and loss function\n",
    "Set the random number generator seed using ```set_seed``` to make everything reproducible.\n",
    "As a criterion use a sensible loss for the multi-class classification problem."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "NMEpCuC1EEFw"
   },
   "source": [
    "### Perform the training of the network and validation\n",
    "Here we provide you with a method to visualize both training and validation loss while training your networks."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "w9txG8N2hzQt",
    "outputId": "85d93faf-2d48-4e9a-8007-6ce50ac15548"
   },
   "outputs": [],
   "source": [
    "def train_model(momentum):\n",
    "  set_seed(seed)\n",
    "  model = LeNet5().to(device)\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "  validation_loader = DataLoader(mnist_validate, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
    "  test_loader = DataLoader(mnist_test, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
    "  \n",
    "  liveloss = PlotLosses()\n",
    "  for epoch in range(30):\n",
    "      logs = {}\n",
    "      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "\n",
    "      logs['' + 'log loss'] = train_loss.item()\n",
    "      logs['' + 'accuracy'] = train_accuracy.item()\n",
    "\n",
    "      validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
    "      logs['val_' + 'log loss'] = validation_loss.item()\n",
    "      logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "\n",
    "      liveloss.update(logs)\n",
    "      liveloss.draw()\n",
    "      \n",
    "  return model\n",
    "\n",
    "model = train_model(0.5)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "5kPt1sm8Mm_q"
   },
   "source": [
    "<br>\n",
    "\n",
    "Results obtained with the feed-forward network from previous session:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/acse-2020/ACSE-8/main/implementation/practical_4/Figs/MNIST_feedforward_cross-validation.png?token=ABNZJP4TNJA6XMPP2CGJMVDATTTU2\" alt=\"results\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "biyWFx8tAW9G"
   },
   "source": [
    "### `code along` Implement an evaluate method\n",
    "This method performs the same as validate but doesn't report losses, but simply returns all predictions on a given dataset (training, validation, test-set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "id": "1-MaI8F1hzQ7"
   },
   "outputs": [],
   "source": [
    "# create a validation_loader and generate predictions\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "keGazNqkAXw9"
   },
   "source": [
    "### `code along` Plotting a confusion matrix\n",
    "\n",
    "We can use a confusion matrix to diagnose problems in our models.\n",
    "We may see for example that our model confuses 9's for 4's quite often."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/"
    },
    "id": "SWtJhZnDhzRE",
    "outputId": "b0ce133d-2c0f-4b7b-da88-eb68921afb40",
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Create a confusion matrix from\n",
    "# print the confusion matrix"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "jKAoFUBevfz7"
   },
   "source": [
    "And plot it to easily visualise where the classifier 'struggles'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 286
    },
    "id": "8fGAVrg4QytH",
    "outputId": "8d11dd44-86af-4753-e894-e6a357194612"
   },
   "outputs": [],
   "source": [
    "import seaborn as sns\n",
    "\n",
    "def to_raw_matrix(cm):\n",
    "    plt_cm = []\n",
    "    for i in cm.classes :\n",
    "        row=[]\n",
    "        for j in cm.classes:\n",
    "            row.append(cm.table[i][j])\n",
    "        plt_cm.append(row)\n",
    "    plt_cm = np.array(plt_cm)\n",
    "    return plt_cm\n",
    "\n",
    "rcm = to_raw_matrix(cm) #store the confusion matrix values\n",
    "\n",
    "sns.heatmap(rcm, cmap=\"Blues\") # use sensible limits to be able to see where the network struggles to identify digits"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "id": "2-OG3gAcE2mr"
   },
   "source": [
    "## `code along` Assume that you have estimated your hyperparameters.\n",
    "\n",
    "Now train your model on the full dataset and evaluate on the test set. How good is the accuracy?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {
     "base_uri": "https://localhost:8080/",
     "height": 689
    },
    "id": "hsHixVU5hzRS",
    "outputId": "046f73fe-abdf-4cef-b055-24a3f14aaf9a"
   },
   "outputs": [],
   "source": [
    "mnist_train = MNIST(\"./\", download=True, train=True) # reload MNIST\n",
    "\n",
    "# check the code from practical_3 if you get stuck.\n",
    "\n",
    "\n",
    "model_save_name = 'LeNet5_mnist_classifier.pt'\n",
    "path = F\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<br>\n",
    "\n",
    "Results obtained with the feed-forward network from previous session:\n",
    "\n",
    "<img src=\"https://raw.githubusercontent.com/acse-2020/ACSE-8/main/implementation/practical_4/Figs/MNIST_feedforward_final_training.png?token=ABNZJPY2YVTCBMJ7LSUOVJTATTUOG\" alt=\"results\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Summary of today's session:\n",
    "\n",
    "- Convolutions as building blocks of CNNs.\n",
    "- Overview of a few PyTorch layers used in CNNs.\n",
    "- LeNet-5 architecture.\n",
    "- Training a network similar to LeNet-5 of MNIST.\n",
    "- Demonstration that CNNs are superior to feed-forward networks because they are aware of the spatial context of the input images."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Custom Datasets and Transforms\n",
    "\n",
    "Pytorch allows us to simply extend the available Datasets to more custom functionality.\n",
    "Here we provide an example of such a custom dataset class.\n",
    "You can see that there are 3 functions we need to implement:\n",
    "- __init__(*args, **kwargs): this will handle everything prior to actually using the dataset\n",
    "- __len__(self): returns the length of the dataset i.e. the number of data items\n",
    "- __getitem__(self, idx): this method takes an index of a specific data item and returns that item.\n",
    "  - You can do whatever you want in these functions: apply transforms, normalize data, perform another computation etc.\n",
    "  - Here we also have the functionality to apply a set of [```torchvision.transforms```](https://pytorch.org/tutorials/beginner/data_loading_tutorial."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.utils.data import Dataset \n",
    "\n",
    "class CustomImageTensorDataset(Dataset):\n",
    "    def __init__(self, data, targets, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            data (Tensor): A tensor containing the data e.g. images\n",
    "            targets (Tensor): A tensor containing all the labels\n",
    "            transform (callable, optional): Optional transform to be applied\n",
    "                on a sample.\n",
    "        \"\"\"\n",
    "        self.data = data\n",
    "        self.targets = targets\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        sample, label = self.data[idx], self.targets[idx]\n",
    "        sample = sample.view(1, 28, 28).float()/255.\n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "\n",
    "        return sample, label"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Transforms\n",
    "\n",
    "Transforms can be used to perform manipulation of individual data prior to passing the data to our models.\n",
    "This is useful for:\n",
    " - Data-augmentation i.e. creating slightly modified instance of the data we have while preserving their labels.\n",
    " - Data Preprocessing: Such as Normalization, Histogram Equalization \n",
    " - Transforming Targets: You may have complex labels that should change together with changes in the preprocessing of the images\n",
    " \n",
    " Pytorch and especially torchvision provides a [number of transforms](https://pytorch.org/docs/stable/torchvision/index.html) for you to use!\n",
    " A nice tutorial on custom dataloaders and transforms can be found [here](https://github.com/utkuozbulak/pytorch-custom-dataset-examples).\n",
    " \n",
    " The (probably) most state-of-the-art library for image augmentation is [albumentations](https://github.com/albu/albumentations) which has been successfully applied in winning kaggle competitions.\n",
    " "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torchvision.transforms import Compose, ToTensor, Normalize, RandomRotation, ToPILImage\n",
    "\n",
    "\n",
    "#Often we will want to apply more transformations at training time than test time, therefore here we have two different ones\n",
    "train_transform = Compose([\n",
    "    ToPILImage(),\n",
    "    RandomRotation(10),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.1307], std=[0.3081]), \n",
    "\n",
    "]) ##Compose different transforms together. PIL is Python Imaging Library useful for opening, manipulating, and saving many different image file formats.\n",
    "\n",
    "#In Validation and Test Mode we only want to normalize our images, because they are already tensors\n",
    "validation_test_transform = Compose([\n",
    "    Normalize(mean=[0.1307], std=[0.3081])\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "<img src=\"https://raw.githubusercontent.com/acse-2020/ACSE-8/main/implementation/practical_4/Figs/data_augmentation.png?token=ABNZJP4FGWYIGD6DLD3KGVDATZENK\" alt=\"network\" width=\"600\"/>\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### `code along` Training with data augmentation\n",
    "\n",
    "- Instantiate a ```CustomImageTensorDataset``` with data from the MNIST dataset\n",
    "- Provide the training and validation and testing datasets with the right transforms\n",
    "- Train LeNet-5 with data-augmentation on a validation set, then train on the full training set and report accuracies. Did you improve the model?\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#### Create the ```CustomImageTensorDataset```:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# download mnist\n",
    "# split in train and validation\n",
    "\n",
    "# create train custom dataset\n",
    "# create validation custom dataset\n",
    "# create test custom dataset\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training LeNet5 with data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model_augmented(train_dataset, validation_dataset, momentum=0.5):\n",
    "  set_seed(seed)\n",
    "  model = LeNet5().to(device)\n",
    "  optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "  criterion = nn.CrossEntropyLoss()\n",
    "  \n",
    "  train_loader = DataLoader(train_dataset, batch_size=batch_size, shuffle=True, num_workers=0)\n",
    "  validation_loader = DataLoader(validation_dataset, batch_size=test_batch_size, shuffle=False, num_workers=0)\n",
    "\n",
    "  liveloss = PlotLosses()\n",
    "  for epoch in range(30):\n",
    "      logs = {}\n",
    "      train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "\n",
    "      logs['' + 'log loss'] = train_loss.item()\n",
    "      logs['' + 'accuracy'] = train_accuracy.item()\n",
    "\n",
    "      validation_loss, validation_accuracy = validate(model, criterion, validation_loader)\n",
    "      logs['val_' + 'log loss'] = validation_loss.item()\n",
    "      logs['val_' + 'accuracy'] = validation_accuracy.item()\n",
    "\n",
    "      liveloss.update(logs)\n",
    "      liveloss.draw()\n",
    "      \n",
    "  return model\n",
    "\n",
    "model = train_model_augmented(custom_mnist_train, mnist_validation)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Training on the full dataset\n",
    "\n",
    "We can apply transforms directly when we get MNIST from [`torchvision.datasets.MNIST`](https://pytorch.org/vision/stable/datasets.html#mnist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mnist_train = MNIST(\"./\", download=True, train=True, transform=Compose([\n",
    "    RandomRotation(10),\n",
    "    ToTensor(),\n",
    "    Normalize(mean=[0.1307], std=[0.3081]), \n",
    "\n",
    "]))\n",
    "train_loader = DataLoader(mnist_train, batch_size=batch_size, shuffle=True, num_workers=4)\n",
    "test_loader = DataLoader(mnist_test, batch_size=test_batch_size, shuffle=False, num_workers=0)    \n",
    "\n",
    "set_seed(seed)\n",
    "model = LeNet5().to(device)\n",
    "optimizer = torch.optim.SGD(model.parameters(), lr=lr, momentum=momentum)\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "liveloss = PlotLosses()\n",
    "for epoch in range(n_epochs):\n",
    "    logs = {}\n",
    "    train_loss, train_accuracy = train(model, optimizer, criterion, train_loader)\n",
    "\n",
    "    logs['' + 'log loss'] = train_loss.item()\n",
    "    logs['' + 'accuracy'] = train_accuracy.item()\n",
    "    liveloss.update(logs)\n",
    "    liveloss.draw()\n",
    "    logs['val_' + 'log loss'] = 0.\n",
    "    logs['val_' + 'accuracy'] = 0.\n",
    "\n",
    "test_loss, test_accuracy = validate(model, criterion, test_loader)    \n",
    "print(\"Avg. Test Loss: %1.3f\" % test_loss.item(), \" Avg. Test Accuracy: %1.3f\" % test_accuracy.item())\n",
    "print(\"\")\n",
    "\n",
    "model_save_name = 'LeNet5_mnist_classifier_with_augmentation.pt'\n",
    "path = F\"/content/gdrive/My Drive/models/{model_save_name}\" \n",
    "torch.save(model.state_dict(), path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### And voila! we have improved a bit more the accuracy of our test set!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "accelerator": "GPU",
  "colab": {
   "collapsed_sections": [],
   "machine_shape": "hm",
   "name": "Morning-Session-4_FromConvolutions_To_ConvNets_Practical.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
